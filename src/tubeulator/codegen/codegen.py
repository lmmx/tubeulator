import ast
import json
import textwrap
from dataclasses import dataclass, field
from itertools import starmap
from pathlib import Path

from ..openapi.scan import scan_namespace
from ..utils.lcp_trie import Trie
from ..utils.paths import find_schema_by_name

__all__ = ["emit_deserialisers"]


def python_type(json_type: str, format: str = None) -> str:
    """
    Map property types in the JSON schema to Python types for type annotation.
    The `format` can be "email" if it's a string but it doesn't change the result.
    """
    type_lookup = {
        "string": "str",
        "integer": "int",
        "boolean": "bool",
        "array": "list",
        "object": "dict",
    }
    return type_lookup.get(json_type, "Any")


def import_node(module: str, names: list[str]) -> ast.Import:
    if names:
        return ast.ImportFrom(module=module, names=[*map(ast.alias, names)], level=0)
    else:
        return ast.Import(names=[ast.alias(name=module)])


@dataclass
class RefPath:
    path: str = field(repr=False)
    name: str = field(init=False)

    def __post_init__(self):
        self.name = Path(self.path).name


@dataclass
class SchemaPath:
    source: dict[str, str] = field(repr=False)
    ref: RefPath = field(init=False)

    def __post_init__(self):
        ref = self.source.get("items", {}).get("$ref")
        self.ref = RefPath(ref)


def generate_dataclass(
    schema: dict,
    idx: int = None,
    name: str | None = None,
    schema_for_ref_lookup: dict | None = None,
    dealiased_name: str | None = None,
    indent_level: int = 1,
) -> str:
    """
    Generate a dataclass from a schema, importing the `field` function if there are any
    array properties requiring it. Use the `idx` to indicate if we're generating
    multiple dataclasses in a loop. (TODO: replace with `schema: dict or list[dict]`)
    """
    schema_name = next(iter(schema_for_ref_lookup))
    monoschema = schema_for_ref_lookup[schema_name]
    ref = schema.get("items", {}).get("$ref")
    # Map names of all schemas in the lookup to their referent (i.e. their array type)
    backrefs = {
        k: SchemaPath(v)
        for k, v in monoschema.items()
        if "items" in v
        if "$ref" in v["items"]
    }
    chased = [
        backref
        for backref, schema_path in backrefs.items()
        if schema_path.ref.name == name
    ]
    # Chase the references if needed
    if len(chased) > 1:
        # Multiple map to the node: they will be different response types
        backref_trie = Trie.from_strings(chased).walk()
        response_types = len(backref_trie)
        app_infix = "Application"
        application_types = next(iter(backref_trie.values()), {}).get(app_infix)
        json_suffix = "JsonResponse"
        err_msg = f"Did not find {json_suffix} in {app_infix} type"
        assert response_types == 1 and json_suffix in application_types, err_msg
        chased_backref = chased[0]
    else:
        chased_backref = chased[0]
    if dealiased_name is not None:
        stem = dealiased_name.rsplit(".", 1)[-1]
        class_name = f"{stem}Deserialiser"
        gen_source = dealiased_name
    elif (name, ref) != (None, None):
        # If they have a name but it's not in namespace, they're a response (targeting $ref)
        breakpoint()
        ref_name = ref.name
        ns = scan_namespace(ignore_responses=True)
        dealiased_ref = (ns[schema_name][ref_name] or [None])[0] or schema_name
        # referent_class_name = f'{dealiased_ref.rsplit(".", 1)[-1]}Deserialiser'
        class_name = f'{dealiased_ref.rsplit(".", 1)[-1]}ResponseDeserialiser'
        gen_source = ref_name
    else:
        gen_source = f"{schema_name}:{idx}"
        class_name = f"{schema_name}Deserialiser{idx if idx is not None else ''}"
        # class_name = schema_name.replace(" ", "") + "Deserialiser"
    class_name = class_name.replace("-", "")
    properties = schema.get("properties", {})
    required = schema.get("required", [])
    contains_list = False
    dc_source = f"@dataclass\nclass {class_name}(JSONWizard):\n"
    docstring = f"Autogenerated from {schema_name}::{gen_source}"
    dc_source += textwrap.indent(f'"""\n{docstring}\n"""\n', " " * indent_level * 4)
    for prop_name, prop_schema in properties.items():
        # breakpoint()
        if "type" not in prop_schema:
            if prop_schema and "$ref" in prop_schema:
                referent = prop_schema["$ref"].replace("#/components/schemas/", "")
                replacement = monoschema[referent]
                # Substitute the reference before accessing the item type
                # prop_schema["items"] = replacement
                # breakpoint() # I don't think it handles nested dataclass arrays!
                # Don't in fact even need to replace in the schema, just the var
                prop_schema = replacement
                # (We could dealias the entity at this point so as to title it?)
        prop_type = python_type(prop_schema["type"], prop_schema.get("format"))
        is_array_prop = prop_schema["type"] == "array"
        if is_array_prop and "items" in prop_schema:
            prop_array = prop_schema["items"]
            # TODO: I think arrays should be handled at level above, check this sooner?
            if "type" not in prop_array:
                if prop_array and "$ref" in prop_array:
                    referent = prop_array["$ref"].replace("#/components/schemas/", "")
                    replacement = monoschema[referent]
                    # Substitute the reference before accessing the item type
                    # prop_schema["items"] = replacement
                    # breakpoint() # I don't think it handles nested dataclass arrays!
                    # Don't in fact even need to replace in the schema, just the var
                    prop_array = replacement
                    # (We could dealias the entity at this point so as to title it?)
            item_type = python_type(prop_array["type"])
            prop_type = f"{prop_type}[{item_type}]"
        if prop_name in required:
            default = ""
        else:
            if is_array_prop:
                contains_list = True
                default = " = field(default_factory=list)"
            else:
                default = " = None"
        dc_source += f"    {prop_name}: {prop_type}{default}\n"
    dc_source += """    @classmethod
    def from_dict(cls, o):
        jsonschema.validate(o, schema)
        return fromdict(cls, o)"""
    import_list = {
        "json": [],
        "dataclasses": ["dataclass"],
        "pathlib": ["Path"],
        "dataclass_wizard": ["JSONWizard", "LoadMeta"],
        "dataclass_wizard.loaders": ["fromdict"],
        "jsonschema": [],
    }
    if contains_list or idx == 0:
        import_list["dataclasses"].append("field")
    imports = "\n".join(map(ast.unparse, starmap(import_node, import_list.items())))
    meta_binding = f"\nLoadMeta(raise_on_unknown_json_key=True).bind_to({class_name})"
    # Add imports here if generating multiple dataclasses [indicated by idx=0] (since we
    # can't see ahead), or if only making 1 [indicated by idx=None]
    output = "\n\n".join([(imports if not idx else ""), dc_source, meta_binding])
    return output


example_schema = {
    "title": "Example Schema",
    "type": "object",
    "properties": {
        "name": {"type": "string"},
        "age": {"type": "integer"},
        "email": {"type": "string", "format": "email"},
        "friends": {"type": "array", "items": {"type": "string"}},
    },
    "required": ["name", "age"],
}


def emit_deserialisers(schema_name: str) -> None:
    endpoint_schema = json.loads(Path(find_schema_by_name(schema_name)).read_text())
    component_schemas = endpoint_schema["components"].get("schemas", {})
    named_monoschema = {schema_name: component_schemas}
    ns = scan_namespace(ignore_responses=True)
    for idx, (component_name, component_schema) in enumerate(component_schemas.items()):
        true_name = (ns.get(schema_name, {}).get(component_name) or [None])[0]
        generated_code = generate_dataclass(
            component_schema,
            idx=idx,
            name=component_name,
            schema_for_ref_lookup=named_monoschema,
            dealiased_name=true_name,
        )
        print(generated_code)
    return
